{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942d9e0-326f-4ec4-8762-8b022f5d5c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --upgrade --quiet google-cloud-aiplatform[agent_engines,adk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f8bb0-f75f-4a46-8ffc-9034e526fd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -U -q \"google-genai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6258d5c-ea0a-448d-acb5-00184eff535a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --quiet gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94373764-e658-45d9-89c9-d63fd79ef313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Set environment variables\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"content-creation-agent-468223\"    #Name of Your Project\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"                     #Location\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"                        #Keep it to true to use Vertex AI\n",
    "os.environ[\"GOOGLE_CLOUD_BUCKET\"] = \"gs://launchpad_marketing\"          #Bucket used for staging\n",
    "os.environ[\"GEMINI_VERSION\"] = \"gemini-2.0-flash\"            #Gemini version: thie model might yield better quality results in terms of nuance, coherence, and creative flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f216460-9160-42ac-9075-6334c8ddb695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Blog Post LLM Agent\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.genai import types\n",
    "from vertexai.preview.reasoning_engines import AdkApp\n",
    "\n",
    "# --- Set safety settings:\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "blog_post_generation_config = types.GenerateContentConfig(\n",
    "   safety_settings = safety_settings,\n",
    "   temperature = 0.75,          # Encourage creativity, stay aligned\n",
    "   max_output_tokens = 4000,    # Allow for 400-500 words comfortably\n",
    "   top_p = 0.85,               # Balance diversity and relevance\n",
    "   presence_penalty = 0.15,    # Small penalty to encourage new ideas/words\n",
    "   frequency_penalty = 0.1,    # Small penalty to reduce repetition of phrases   \n",
    ")\n",
    "\n",
    "\n",
    "blog_post_instructions = \"\"\"\n",
    "You are a junior copywriter tasked with creating a compelling product announcement blog post.\n",
    "Goal: Write an engaging, well-structured blog post of 400â€“500 words based on the provided product brief.\n",
    "\n",
    "Your responsibilities:\n",
    "1.  **Accept and Integrate Product Brief:** You will be provided with a product brief containing:\n",
    "    *   Product Name: The official name of the product.\n",
    "    *   Short Description: A concise summary of what the product is.\n",
    "    *   Key Features: A list of the product's main functionalities or attributes\n",
    "    *   Target Audience: A description of the intended readers.\n",
    "\n",
    "2.  **Content Crafting:**\n",
    "    *   Craft the content in a clear, accessible, and enthusiastic tone suited for the **Target Audience**.\n",
    "    *   Elaborate on the **Key Features**, translating them into tangible benefits and solving problems for the **Target Audience**.\n",
    "    *   **Infer and highlight the product's unique advantages** based on the provided description and features, without needing an explicit USP statement from the user.\n",
    "\n",
    "3.  **Structure the Blog Post:**\n",
    "    *   **Title:** Create a compelling, SEO-friendly title that clearly communicates the product launch and generates curiosity.\n",
    "    *   **Introduction:** Start with a relatable problem or aspiration of the **Target Audience**, then introduce the product as the solution, briefly mentioning its core purpose. Hook the reader's interest.\n",
    "    *   **Body:** Expand on the productâ€™s benefits, use cases, and **Key Features** in 2â€“3 well-developed paragraphs. Each paragraph should ideally focus on a key benefit or set of related features. Emphasize what makes the product stand out based on the provided information.\n",
    "    *   **Conclusion:** Summarize the main selling points and the core value proposition of the product. End with a general, encouraging closing statement that prompts further exploration or interest, without a specific \"call to action\" directive.\n",
    "\n",
    "4.  **Tone and Language:**\n",
    "    *   Avoid overly technical jargon unless the **Target Audience** is explicitly technical.\n",
    "    *   Maintain a friendly, enthusiastic, yet professional tone throughout the post. Convey excitement about the product without making unsubstantiated claims.\n",
    "\n",
    "Output Format:\n",
    "*   Provide the blog post as markdown, using clear section headings for Title, Introduction, Body, and Conclusion.\n",
    "*   Do not include any placeholder text or filler phrases; fully write out all sections with complete sentences and paragraphs.\n",
    "*   Strive for a word count between 400 and 500 words, ensuring each sentence adds value and contributes to the overall narrative.\n",
    "\"\"\"\n",
    "\n",
    "blog_post_agent = LlmAgent(\n",
    "    name=\"BlogPostAgent\", \n",
    "    model = os.getenv(\"GEMINI_VERSION\"),\n",
    "    description=(\"Agent that writes a 400-500 word announcement blog post\"),\n",
    "    instruction=blog_post_instructions, \n",
    "    generate_content_config=blog_post_generation_config,\n",
    "    output_key=\"blog_post_result\")\n",
    "\n",
    "blog_app = AdkApp(agent=blog_post_agent)\n",
    "print(\"âœ… BlogPostAgent is ready to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4551f-6213-4631-b25d-a2f507e63a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Local test of Blog Agent\n",
    "for event in blog_app.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    message=\"\"\"I want to announce a new product called VisionLink Pro.\n",
    "                Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration.\n",
    "                The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video.\n",
    "                The target audience is remote teams, global companies, and project managers.\n",
    "                \"\"\",):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b821aba-9869-4061-a5b3-8b73beafc81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Social Media LLM Agent\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.genai import types\n",
    "from vertexai.preview.reasoning_engines import AdkApp\n",
    "\n",
    "social_media_generation_config = types.GenerateContentConfig(\n",
    "    safety_settings=safety_settings, # Reuse your existing safety settings\n",
    "    temperature=0.85,          # Higher temp for more creative variations\n",
    "    max_output_tokens=4000,     # Enough for 3 short posts + JSON structure\n",
    "    top_p=0.9,                 # Allow more diversity for platform variations\n",
    "    presence_penalty=0.2,      # Encourage more distinct phrasing across platforms\n",
    "    frequency_penalty=0.15,    # Reduce repetition within and between posts\n",
    ")\n",
    "\n",
    "social_media_instructions = \"\"\"\n",
    "You are a Social Media Coordinator tasked with creating a set of promotional posts for a new product launch.\n",
    "Goal: Generate a variety of engaging, platform-specific social media posts based on the provided product brief. If specific platforms are requested, generate posts for those; otherwise, default to LinkedIn, X/Twitter, and Instagram. The output must be in JSON format.\n",
    "\n",
    "Your responsibilities:\n",
    "1.  **Accept and Integrate Product Brief and Target Platforms:** You will be provided with:\n",
    "    *   A product brief containing:\n",
    "        *   Product Name: The official name of the product.\n",
    "        *   Short Description: A concise summary of what the product is.\n",
    "        *   Key Features: A list of the product's main functionalities or attributes.\n",
    "        *   Target Audience: A description of the intended readers.\n",
    "    *   Optionally, a list of target social media platforms provided by the user. If no platforms are provided, **default to LinkedIn, X/Twitter, and Instagram.**\n",
    "\n",
    "2.  **Content Crafting & Platform Adaptation:**\n",
    "    *   **Analyze the Product Brief:** Understand the product's core value and its appeal to the `Target Audience`.\n",
    "    *   **Platform Tailoring:** For **each** platform specified by the user (or the default platforms if none are specified), generate a distinct post optimized for that platform. Consider their unique tones, lengths, and best practices.\n",
    "    *   **Supported Platforms & Styles:**\n",
    "        *   **LinkedIn:** Professional, benefit-driven, suitable for a business/professional audience. Focus on problem-solving and value proposition. Use relevant professional hashtags.\n",
    "        *   **X/Twitter:** Concise, attention-grabbing, and punchy. Use relevant trending or product-specific hashtags. Aim for high impact in a short space.\n",
    "        *   **Instagram:** Engaging, visually-oriented caption that complements an assumed product image. Use a friendly, enthusiastic tone. Include relevant hashtags for broader reach and engagement.\n",
    "        *   **Facebook:** Conversational, potentially slightly longer than Twitter, but still engaging. Can include links and a good mix of benefits and enthusiasm. Use relevant hashtags.\n",
    "        *   **(Add other platforms here if you want to pre-define their styles, e.g., TikTok, Pinterest)**\n",
    "    *   **Infuse Product Highlights:** Weave in key benefits derived from the `Key Features` and the product's essence into each post.\n",
    "\n",
    "3.  **Output Structure:**\n",
    "    *   Your final output must be a **JSON object**.\n",
    "    *   The JSON object should contain keys corresponding to each requested or defaulted platform (e.g., `linkedin_post`, `twitter_post`, `instagram_caption`, `facebook_post`). Use lowercase, snake_case for platform names in the keys.\n",
    "    *   Example JSON structure:\n",
    "        ```json\n",
    "        {\n",
    "          \"linkedin_post\": \"Your professionally crafted LinkedIn post text here...\",\n",
    "          \"twitter_post\": \"Your concise and punchy X/Twitter post text here...\",\n",
    "          \"instagram_caption\": \"Your engaging Instagram caption text here...\"\n",
    "        }\n",
    "        ```\n",
    "    *   Ensure the text within each platform's key is a complete and well-formed social media post.\n",
    "\n",
    "4.  **Tone and Language:**\n",
    "    *   Maintain an enthusiastic and clear tone across all platforms.\n",
    "    *   Adapt the tone slightly for each platform as described above.\n",
    "    *   Avoid overly technical jargon unless the `Target Audience` specifically indicates a technical focus.\n",
    "    *   Use emojis judiciously where appropriate for the platform and tone.\n",
    "\n",
    "Output Format:\n",
    "*   Provide the output as a JSON string.\n",
    "*   Do not include any introductory or concluding remarks outside of the JSON object itself.\n",
    "*   Ensure the generated posts are of appropriate length for each platform:\n",
    "    *   LinkedIn: Aim for impactful, professional content.\n",
    "    *   X/Twitter: Under 280 characters.\n",
    "    *   Instagram Caption: Core message within the first few lines, engaging tone.\n",
    "    *   Facebook: Conversational, engaging.\n",
    "    *   **(Adjust length guidelines for any other platforms you add)**\n",
    "\"\"\"\n",
    "\n",
    "social_media_agent = LlmAgent(\n",
    "    name=\"SocialMediaAgent\", \n",
    "    model = os.getenv(\"GEMINI_VERSION\"),\n",
    "    description=(\"Agent that generates multi-platform short-form posts in structured JSON.\"),\n",
    "    instruction=social_media_instructions, \n",
    "    generate_content_config=social_media_generation_config,\n",
    "    output_key=\"social_media_result\")\n",
    "\n",
    "social_app = AdkApp(agent=social_media_agent)\n",
    "print(\"âœ… SocialMediaAgent is ready to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1b671-0032-4f80-9fa7-c269c70e0c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Local Test of Social Media Agent\n",
    "for event in social_app.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    message=\"\"\"\n",
    "    I want to announce a new product called VisionLink Pro.\n",
    "    Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration.\n",
    "    The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video.\n",
    "    The target audience is remote teams, global companies, and project managers.\n",
    "    \"\"\",):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed2499-ff93-48cc-a0be-7deafc89deb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.adk.agents import SequentialAgent\n",
    "\n",
    "# --- Create Coordinator LLM Agent\n",
    "consolidator_instructions = \"\"\"\n",
    "You must follow these steps in order and without deviation.\n",
    "\n",
    "1.  **Receive and Validate User Input:**\n",
    "    *   **Action:** Analyze the user's input message to identify the components of a product brief: `Product Name`, `Short Description`, `Key Features`, `Target Audience`, and an optional list of `Target Platforms`.\n",
    "    *   **Validation Rule:** Before proceeding, you **must** confirm that all four essential components (`Product Name`, `Short Description`, `Key Features`, `Target Audience`) are present.\n",
    "    *   **Handling Incomplete Input:**\n",
    "        *   **If ANY essential component is missing, your ONLY valid action is to ask the user for the specific missing information.** Do not proceed. Do not call any agents.\n",
    "        *   *Example 1:* If `Key Features` are missing, respond with: \"I have the product name and description, but I need the Key Features to proceed. Could you list them?\"\n",
    "        *   *Example 2:* If multiple are missing, respond with: \"To generate your campaign package, I need the Product Name and Target Audience. Could you please provide these details?\"\n",
    "\n",
    "\n",
    "2. Consolidate {blog_post_result} and {social_media_result} in the following output format:\n",
    "\n",
    "    ```markdown\n",
    "    # Campaign Package: [Product Name]\n",
    "    ---\n",
    "    ## Blog Post\n",
    "\n",
    "    (Insert the full markdown output from the {blog_post_result} here. This section must be exactly as provided, preserving all markdown formatting but remove the delimiters.)\n",
    "    ---\n",
    "    ## Social Media Posts\n",
    "\n",
    "    (Insert the formatted list of social media posts here. You must parse the JSON from {social_media_result} and present it as a markdown list.)\n",
    "    *   **LinkedIn:** [Text of the LinkedIn post]\n",
    "    *   **X/Twitter:** [Text of the X/Twitter post]\n",
    "    *   **Instagram:** [Text of the Instagram caption]\n",
    "    *   (Add other platforms as needed, following this bulleted format.)\n",
    "    ---\n",
    "    ```\n",
    "\"\"\"\n",
    "\n",
    "consolidator_generation_config = types.GenerateContentConfig(\n",
    "    temperature=0.3,  # Lower temperature for logical orchestration, control, and reliability\n",
    "    max_output_tokens=8000, # Sufficient for two agent outputs plus markdown wrapper\n",
    "    top_p=0.7,        # More controlled sampling\n",
    "    presence_penalty=0.0,\n",
    "    frequency_penalty=0.0,\n",
    ")\n",
    "\n",
    "consolidator_agent = LlmAgent(\n",
    "    name=\"CoordinatorAgent\",\n",
    "    model = os.getenv(\"GEMINI_VERSION\"),\n",
    "    instruction=consolidator_instructions,\n",
    "    description=\"Campaign Coordinator\",\n",
    "    generate_content_config=consolidator_generation_config,\n",
    "    output_key=\"consolidator_result\",\n",
    ")\n",
    "\n",
    "coordinator_agent = SequentialAgent(name=\"Coordinator\", sub_agents=[blog_post_agent, social_media_agent, consolidator_agent])\n",
    "\n",
    "# Create an AdkApp that includes all your agents\n",
    "# This allows the coordinator agent to find and use the other agents as tools.\n",
    "coordinator_app = AdkApp(agent=coordinator_agent)\n",
    "\n",
    "print(\"âœ… CoordinatorAgent is ready to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4c15f-8d5f-470b-90c5-005be0d8a0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Iterate through ALL events yielded by the stream query\n",
    "for event in coordinator_app.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    message=\"\"\" \n",
    "            I want a blog post for VisionLink Pro.\n",
    "            Description: Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration.\n",
    "            key features:  support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video.\n",
    "            The target audience is remote teams, global companies, and project managers.\n",
    "            Platforms: LinkedIn, Instagram\n",
    "            \"\"\",\n",
    "):\n",
    "    print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917bd80-d38e-4149-aba0-5bf8e51f96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Deploy all Agents in Vertex AI Agent Engine (Wait for Creation of all agents before moving on...)\n",
    "import vertexai\n",
    "\n",
    "from vertexai import agent_engines\n",
    "\n",
    "# --- Init Vertex AI Environment ---\n",
    "vertexai.init(\n",
    "    project= os.getenv(\"GOOGLE_CLOUD_PROJECT\"),\n",
    "    location= os.getenv(\"GOOGLE_CLOUD_LOCATION\"),\n",
    "    staging_bucket= os.getenv(\"GOOGLE_CLOUD_BUCKET\"), \n",
    ")\n",
    "\n",
    "# --- Deploy Blog Post Agent ---\n",
    "remote_blog_agent = agent_engines.create(\n",
    "    blog_app,\n",
    "    display_name=\"Blog Post Agent\",\n",
    "    description=\"Writes 400â€“500 word product announcement posts in Markdown.\",\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"],  #\"cloudpickle==3.1.1\",\"pydantic==2.11.7\"\n",
    ")\n",
    "print(\"âœ… Blog Post Agent created on Vertex AI Agent Engine\")\n",
    "\n",
    "# --- Deploy Social Media Agent ---\n",
    "remote_social_agent = agent_engines.create(\n",
    "    social_app,\n",
    "    display_name=\"Social Media Agent\",\n",
    "    description=\"Generates multi-platform short-form posts in structured JSON from a product brief.\",\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"], \n",
    ")\n",
    "print(\"âœ… Social Media Agent created on Vertex AI Agent Engine\")\n",
    "\n",
    "# --- Deploy Campaign Coordinator Agent ---\n",
    "remote_campaign_coordinator_agent = agent_engines.create(\n",
    "    coordinator_app,\n",
    "    display_name=\"Campaign Coordinator Agent\",\n",
    "    description=\"Orchestrates Blog Post and Social Media Agents to produce a unified campaign package.\",\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"],\n",
    ")\n",
    "print(\"âœ… Campaign Coordinator Agent created on Vertex AI Agent Engine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac398de6-69f0-4831-b54d-a50dbcd4f069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Test consolidation of Blog + Social Media Agent\n",
    "remote_session = remote_campaign_coordinator_agent.create_session(user_id=\"user_123\")\n",
    "\n",
    "for event in remote_campaign_coordinator_agent.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    session_id = remote_session[\"id\"],\n",
    "    message=\"\"\"I want to announce a new product called VisionLink Pro.\n",
    "                Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration. \n",
    "                The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video. \n",
    "                The target audience is remote teams, global companies, and project managers.\"\"\"\n",
    "   ):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a311090-2e59-4ba6-afea-00618ba9afec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Gradio GUI â€“ Multi-Agent Chat (Coordinator / Blog / Social)\n",
    "# - Per-agent sessions on Agent Engine\n",
    "# - Chatbot (messages mode) on the right with markdown rendering\n",
    "# - Left pane: agent picker, prompt, Send, Start New Session\n",
    "# - Agents emit one of:\n",
    "#   consolidator_result / social_media_result / blog_post_result\n",
    "# - Rule: if consolidator_result is present, do NOT display social/blog results\n",
    "# - Extra: unwrap inner ```markdown block under \"## Blog Post\" in consolidator_result\n",
    "#          and strip any trailing ``` fence lines\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "import gradio as gr\n",
    "\n",
    "USER_ID = \"user_123\"\n",
    "\n",
    "# ---- Plug in your deployed remote agent handles here ----\n",
    "# Example:\n",
    "#   remote_campaign_coordinator_agent = agent_engines.get(\"...id...\")\n",
    "#   remote_blog_agent = agent_engines.get(\"...id...\")\n",
    "#   remote_social_agent = agent_engines.get(\"...id...\")\n",
    "REMOTE_HANDLES = {\n",
    "    \"Campaign Coordinator Agent\": remote_campaign_coordinator_agent,\n",
    "    \"Blog Post Agent\": remote_blog_agent,\n",
    "    \"Social Media Agent\": remote_social_agent,\n",
    "}\n",
    "\n",
    "# --- Result keys (priority order) ---\n",
    "OUTPUT_KEYS = (\"consolidator_result\", \"social_media_result\", \"blog_post_result\")\n",
    "\n",
    "def _jsonify_if_needed(v):\n",
    "    if isinstance(v, (dict, list)):\n",
    "        try:\n",
    "            return json.dumps(v, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            return str(v)\n",
    "    return v if isinstance(v, str) else str(v)\n",
    "\n",
    "# ---------- Helpers to pull text from various event shapes ----------\n",
    "\n",
    "def _extract_text_from_content(content: dict) -> str:\n",
    "    parts = (content or {}).get(\"parts\") or []\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        t = p.get(\"text\")\n",
    "        if isinstance(t, str) and t.strip():\n",
    "            out.append(t.strip()); continue\n",
    "        inline = p.get(\"inline_data\", {})\n",
    "        data = inline.get(\"data\")\n",
    "        if isinstance(data, str):\n",
    "            try:\n",
    "                out.append(base64.b64decode(data).decode(\"utf-8\", errors=\"ignore\").strip())\n",
    "            except Exception:\n",
    "                pass\n",
    "    return \"\\n\".join([x for x in out if x])\n",
    "\n",
    "def _collect_outputs(ev):\n",
    "    \"\"\"\n",
    "    Return a list of (key, text) found in the event.\n",
    "    Keys are one of OUTPUT_KEYS when detectable, else None for generic content.\n",
    "    Looks in actions.state_delta, top-level fields, and candidates[*].actions.state_delta.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    if not isinstance(ev, dict):\n",
    "        return results\n",
    "\n",
    "    # 1) Primary: actions.state_delta\n",
    "    sd = ((ev.get(\"actions\") or {}).get(\"state_delta\") or {})\n",
    "    if isinstance(sd, dict):\n",
    "        for k in OUTPUT_KEYS:\n",
    "            if k in sd:\n",
    "                results.append((k, _jsonify_if_needed(sd[k])))\n",
    "\n",
    "    # 2) Top-level keys (fallback, if any)\n",
    "    for k in OUTPUT_KEYS:\n",
    "        if k in ev:\n",
    "            results.append((k, _jsonify_if_needed(ev[k])))\n",
    "\n",
    "    # 3) Candidates (rare, but supported)\n",
    "    cands = ev.get(\"candidates\")\n",
    "    if isinstance(cands, list):\n",
    "        for c in cands:\n",
    "            if not isinstance(c, dict):\n",
    "                continue\n",
    "            csd = ((c.get(\"actions\") or {}).get(\"state_delta\") or {})\n",
    "            if isinstance(csd, dict):\n",
    "                for k in OUTPUT_KEYS:\n",
    "                    if k in csd:\n",
    "                        results.append((k, _jsonify_if_needed(csd[k])))\n",
    "\n",
    "    # 4) Generic content text (only if no keyed outputs on this event)\n",
    "    if not results:\n",
    "        if isinstance(ev.get(\"content\"), dict):\n",
    "            s = _extract_text_from_content(ev[\"content\"])\n",
    "            if s:\n",
    "                results.append((None, s))\n",
    "        elif isinstance(ev.get(\"message\"), dict) and isinstance(ev[\"message\"].get(\"content\"), dict):\n",
    "            s = _extract_text_from_content(ev[\"message\"][\"content\"])\n",
    "            if s:\n",
    "                results.append((None, s))\n",
    "\n",
    "    return results\n",
    "\n",
    "def call_engine_once(remote_engine_handle, prompt: str, session_id: str, user_id: str = USER_ID):\n",
    "    \"\"\"\n",
    "    Streams events and assembles (text, consolidator_seen).\n",
    "    IMPORTANT: If any event contains consolidator_result, we ONLY keep consolidator chunks\n",
    "               and ignore social_media_result/blog_post_result (and any other chunks).\n",
    "    \"\"\"\n",
    "    consolidator_seen = False\n",
    "    consolidator_chunks = []\n",
    "    other_chunks = []\n",
    "\n",
    "    for ev in remote_engine_handle.stream_query(user_id=user_id, message=prompt, session_id=session_id):\n",
    "        outputs = _collect_outputs(ev)\n",
    "        if not outputs:\n",
    "            continue\n",
    "\n",
    "        # If we see consolidator in this event, switch to consolidator-only mode\n",
    "        this_has_consolidator = any(k == \"consolidator_result\" for k, _ in outputs)\n",
    "\n",
    "        if this_has_consolidator:\n",
    "            if not consolidator_seen:\n",
    "                consolidator_seen = True\n",
    "                other_chunks = []  # drop anything gathered earlier\n",
    "            for k, piece in outputs:\n",
    "                if k == \"consolidator_result\" and isinstance(piece, str) and piece.strip():\n",
    "                    consolidator_chunks.append(piece.strip())\n",
    "            # ignore any non-consolidator outputs in this event\n",
    "            continue\n",
    "\n",
    "        if consolidator_seen:\n",
    "            # Once consolidator is seen, ignore everything else\n",
    "            continue\n",
    "\n",
    "        # No consolidator yet â†’ accept social/blog/generic\n",
    "        for k, piece in outputs:\n",
    "            if isinstance(piece, str) and piece.strip():\n",
    "                other_chunks.append(piece.strip())\n",
    "\n",
    "    aggregated = \"\\n\".join(consolidator_chunks) if consolidator_seen else \"\\n\".join(other_chunks)\n",
    "    return aggregated.strip(), consolidator_seen\n",
    "\n",
    "# ---------- Rendering helpers ----------\n",
    "\n",
    "def _unfence(s: str):\n",
    "    \"\"\"\n",
    "    If `s` is code-fenced (``` or ```lang), return (inner_text, language).\n",
    "    Otherwise return (s, \"\").\n",
    "    \"\"\"\n",
    "    s = (s or \"\").strip()\n",
    "    if not s.startswith(\"```\"):\n",
    "        return s, \"\"\n",
    "    lines = s.splitlines()\n",
    "    if len(lines) >= 2 and lines[-1].strip() == \"```\" and lines[0].startswith(\"```\"):\n",
    "        lang = lines[0][3:].strip().lower()  # e.g., \"markdown\", \"md\", \"json\"\n",
    "        inner = \"\\n\".join(lines[1:-1]).strip()\n",
    "        return inner, lang\n",
    "    return s, \"\"\n",
    "\n",
    "def _unwrap_blog_markdown(md: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove any lines that are only ``` / ```markdown / ```md inside the\n",
    "    '## Blog Post' section so the inner block renders as normal markdown.\n",
    "    \"\"\"\n",
    "    fence_pat = re.compile(r\"^```\\s*(?:markdown|md)?\\s*$\", re.IGNORECASE)\n",
    "\n",
    "    lines = md.splitlines()\n",
    "\n",
    "    # find the Blog Post H2\n",
    "    blog_start = -1\n",
    "    for i, ln in enumerate(lines):\n",
    "        if ln.strip().lower().startswith(\"## blog post\"):\n",
    "            blog_start = i\n",
    "            break\n",
    "    if blog_start == -1:\n",
    "        return md\n",
    "\n",
    "    # find the next H2 (end of Blog section) or EOF\n",
    "    blog_end = len(lines)\n",
    "    for i in range(blog_start + 1, len(lines)):\n",
    "        if lines[i].strip().startswith(\"## \"):\n",
    "            blog_end = i\n",
    "            break\n",
    "\n",
    "    # Strip fence lines inside the Blog section\n",
    "    cleaned = []\n",
    "    for ln in lines[blog_start + 1:blog_end]:\n",
    "        if fence_pat.match(ln.strip()):\n",
    "            continue\n",
    "        cleaned.append(ln)\n",
    "\n",
    "    new_lines = lines[:blog_start + 1] + cleaned + lines[blog_end:]\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "def _strip_trailing_fences(md: str) -> str:\n",
    "    fence_only = re.compile(r\"^```\\s*$\")\n",
    "    lines = md.splitlines()\n",
    "    while lines and fence_only.match(lines[-1].strip()):\n",
    "        lines.pop()\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def parse_result_payload(raw_text: str, is_consolidator: bool):\n",
    "    \"\"\"\n",
    "    Returns (mode, value)\n",
    "      mode in {\"markdown\", \"json\", \"raw\"}\n",
    "      value is a string (markdown) or a dict/list (json)\n",
    "\n",
    "    Rules:\n",
    "      - Prefer markdown if the payload is fenced as ```markdown / ```md.\n",
    "      - If unfenced string: try JSON if it looks like JSON, else markdown.\n",
    "      - When is_consolidator=True and mode=='markdown', unwrap the inner blog block and strip trailing fences.\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_text, str):\n",
    "        return (\"raw\", str(raw_text))\n",
    "\n",
    "    text = raw_text.strip()\n",
    "\n",
    "    # Whole payload as JSON?\n",
    "    payload = None\n",
    "    if text.startswith(\"{\") or text.startswith(\"[\"):\n",
    "        try:\n",
    "            payload = json.loads(text)\n",
    "        except Exception:\n",
    "            payload = None\n",
    "\n",
    "    if isinstance(payload, (dict, list)):\n",
    "        return (\"json\", payload)\n",
    "\n",
    "    # Check for fenced payload\n",
    "    inner, lang = _unfence(text)\n",
    "    if inner != text:\n",
    "        if lang in (\"json\", \"jsonc\", \"javascript\"):\n",
    "            try:\n",
    "                return (\"json\", json.loads(inner))\n",
    "            except Exception:\n",
    "                return (\"markdown\", inner)\n",
    "        # markdown (or unknown) â†’ treat as markdown text\n",
    "        md = inner\n",
    "        if is_consolidator:\n",
    "            md = _unwrap_blog_markdown(md)\n",
    "            md = _strip_trailing_fences(md)\n",
    "        return (\"markdown\", md)\n",
    "\n",
    "    # Unfenced: try JSON-looking, else markdown\n",
    "    s2 = text.lstrip()\n",
    "    if s2.startswith(\"{\") or s2.startswith(\"[\"):\n",
    "        try:\n",
    "            return (\"json\", json.loads(text))\n",
    "        except Exception:\n",
    "            pass\n",
    "    md = text\n",
    "    if is_consolidator:\n",
    "        md = _unwrap_blog_markdown(md)\n",
    "        md = _strip_trailing_fences(md)\n",
    "    return (\"markdown\", md)\n",
    "\n",
    "def to_markdown(value) -> str:\n",
    "    \"\"\"\n",
    "    Format dict/list values as pretty JSON fenced in code blocks.\n",
    "    Leave strings as-is so markdown renders naturally.\n",
    "    \"\"\"\n",
    "    if isinstance(value, (dict, list)):\n",
    "        return \"```json\\n\" + json.dumps(value, indent=2, ensure_ascii=False) + \"\\n```\"\n",
    "    return str(value)\n",
    "\n",
    "# ---------- Gradio callbacks (messages mode) ----------\n",
    "\n",
    "def ensure_session(agent_name: str, sessions: dict):\n",
    "    sessions = sessions or {}\n",
    "    info = sessions.get(agent_name, {})\n",
    "    sid = info.get(\"session_id\")\n",
    "    if sid:\n",
    "        return sid, sessions\n",
    "    remote = REMOTE_HANDLES[agent_name]\n",
    "    sess = remote.create_session(user_id=USER_ID)\n",
    "    sid = getattr(sess, \"id\", None) or (sess.get(\"id\") if isinstance(sess, dict) else str(sess))\n",
    "    sessions[agent_name] = {\"session_id\": sid}\n",
    "    return sid, sessions\n",
    "\n",
    "def start_new_session(agent_name: str, sessions: dict, chats: dict):\n",
    "    if not agent_name:\n",
    "        return \"Select an agent first.\", sessions, chats\n",
    "    remote = REMOTE_HANDLES[agent_name]\n",
    "    sess = remote.create_session(user_id=USER_ID)\n",
    "    sid = getattr(sess, \"id\", None) or (sess.get(\"id\") if isinstance(sess, dict) else str(sess))\n",
    "    sessions = sessions or {}\n",
    "    sessions[agent_name] = {\"session_id\": sid}\n",
    "    chats = chats or {}\n",
    "    chats[agent_name] = []  # messages mode: list of dicts [{role, content}]\n",
    "    return f\"Started a new session for **{agent_name}**.\", sessions, chats\n",
    "\n",
    "def send(agent_name: str, prompt: str, sessions: dict, chats: dict):\n",
    "    if not agent_name:\n",
    "        return \"Please select an agent.\", sessions, chats, gr.update()\n",
    "    if not prompt or not prompt.strip():\n",
    "        return \"Type something to send.\", sessions, chats, gr.update()\n",
    "\n",
    "    sid, sessions = ensure_session(agent_name, sessions)\n",
    "    remote = REMOTE_HANDLES[agent_name]\n",
    "\n",
    "    try:\n",
    "        aggregated, is_consolidator = call_engine_once(remote, prompt, sid, user_id=USER_ID)\n",
    "    except Exception as e:\n",
    "        aggregated, is_consolidator = f\"**SDK error**: {e}\", False\n",
    "\n",
    "    mode, value = parse_result_payload(aggregated, is_consolidator=is_consolidator)\n",
    "    assistant_md = to_markdown(value) if mode == \"json\" else value  # don't fence markdown\n",
    "\n",
    "    chats = chats or {}\n",
    "    history = chats.get(agent_name) or []\n",
    "    history = history + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_md},\n",
    "    ]\n",
    "    chats[agent_name] = history\n",
    "\n",
    "    return \"\", sessions, chats, gr.update(value=\"\")\n",
    "\n",
    "def render_chat(agent_name: str, chats: dict):\n",
    "    chats = chats or {}\n",
    "    return chats.get(agent_name) or []\n",
    "\n",
    "# ---------- UI ----------\n",
    "\n",
    "with gr.Blocks(title=\"LaunchPad â€“ Multi-Agent Chat\") as demo:\n",
    "    gr.Markdown(\"## ðŸ§  LaunchPad â€“ Multi-Agent Campaign Builders\")\n",
    "\n",
    "    with gr.Row():\n",
    "        # Left Pane\n",
    "        with gr.Column(scale=5):\n",
    "            agent_dd = gr.Dropdown(\n",
    "                choices=list(REMOTE_HANDLES.keys()),\n",
    "                value=\"Campaign Coordinator Agent\",\n",
    "                label=\"Select Agent\",\n",
    "            )\n",
    "            prompt_tb = gr.Textbox(\n",
    "                label=\"Prompt\",\n",
    "                placeholder=\"Paste your product brief or type a requestâ€¦\",\n",
    "                lines=8,\n",
    "            )\n",
    "            with gr.Row():\n",
    "                send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "                new_sess_btn = gr.Button(\"Start New Session (for selected agent)\")\n",
    "            status_md = gr.Markdown(\"\", elem_id=\"status\")\n",
    "\n",
    "        # Right Pane\n",
    "        with gr.Column(scale=7):\n",
    "            chat = gr.Chatbot(\n",
    "                label=\"Conversation\",\n",
    "                type=\"messages\",\n",
    "                height=550,\n",
    "                render_markdown=True,\n",
    "                sanitize_html=False\n",
    "            )\n",
    "\n",
    "    sessions_state = gr.State({k: {} for k in REMOTE_HANDLES.keys()})\n",
    "    chats_state = gr.State({k: [] for k in REMOTE_HANDLES.keys()})\n",
    "\n",
    "    send_btn.click(\n",
    "        send,\n",
    "        inputs=[agent_dd, prompt_tb, sessions_state, chats_state],\n",
    "        outputs=[status_md, sessions_state, chats_state, prompt_tb],\n",
    "    ).then(\n",
    "        render_chat,\n",
    "        inputs=[agent_dd, chats_state],\n",
    "        outputs=[chat],\n",
    "    )\n",
    "\n",
    "    new_sess_btn.click(\n",
    "        start_new_session,\n",
    "        inputs=[agent_dd, sessions_state, chats_state],\n",
    "        outputs=[status_md, sessions_state, chats_state],\n",
    "    ).then(\n",
    "        render_chat,\n",
    "        inputs=[agent_dd, chats_state],\n",
    "        outputs=[chat],\n",
    "    )\n",
    "\n",
    "    agent_dd.change(\n",
    "        render_chat,\n",
    "        inputs=[agent_dd, chats_state],\n",
    "        outputs=[chat],\n",
    "    )\n",
    "\n",
    "# Set share=True if you want a public link; otherwise omit.\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd281a-dad8-45d3-985c-b70118c30bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cleanup Turn Off UI\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f540a-2f8e-474c-8ee3-38d1d1cf2b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cleanup Delete Deployed Agents\n",
    "remote_blog_agent.delete(force=True)\n",
    "remote_social_agent.delete(force=True)\n",
    "remote_campaign_coordinator_agent.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363fd3c-0b24-4f02-b891-87c9ba4e5d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
