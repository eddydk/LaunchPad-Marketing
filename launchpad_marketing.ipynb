{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942d9e0-326f-4ec4-8762-8b022f5d5c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --upgrade --quiet google-cloud-aiplatform[agent_engines,adk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f8bb0-f75f-4a46-8ffc-9034e526fd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -U -q \"google-genai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6258d5c-ea0a-448d-acb5-00184eff535a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --quiet gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94373764-e658-45d9-89c9-d63fd79ef313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Set environment variables\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"content-creation-agent-468223\"    #Name of Your Project\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\"                     #Location\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"                        #Keep it to true to use Vertex AI\n",
    "os.environ[\"GOOGLE_CLOUD_BUCKET\"] = \"gs://launchpad_marketing\"          #Bucket used for staging\n",
    "os.environ[\"GEMINI_VERSION\"] = \"gemini-2.0-flash\"                       #Gemini version to use for Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f216460-9160-42ac-9075-6334c8ddb695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Blog Post LLM Agent\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.genai import types\n",
    "from vertexai.preview.reasoning_engines import AdkApp\n",
    "\n",
    "# --- Set safety settings:\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "]\n",
    "\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "   safety_settings=safety_settings,\n",
    "   temperature=0.7,\n",
    "   max_output_tokens= 800,\n",
    "   top_p= 0.95,\n",
    ")\n",
    "\n",
    "\n",
    "blog_post_instructions = \"\"\"\n",
    "            You are a junior copywriter tasked with creating a product announcement blog post.\n",
    "            Goal: Write an engaging, well-structured blog post of 500â€“600 words based on the provided product brief.\n",
    "            Your responsibilities:\n",
    "                1. Accept a simple product brief with:\n",
    "                    - Product Name\n",
    "                    - Short Description\n",
    "                    - Key Features (bullet list)\n",
    "                    - Target Audience\n",
    "                2. Craft the content in a clear, accessible tone suited for the target audience.\n",
    "                3. Structure the blog post with the following sections:\n",
    "                    - Title: Compelling and relevant to the product launch.\n",
    "                    - Introduction: Briefly introduce the product and hook the readerâ€™s interest.\n",
    "                    - Body: Expand on the productâ€™s benefits, use cases, and key features in 2â€“3 short paragraphs.\n",
    "                    - Conclusion: Summarize the main selling points and end with a clear call-to-action.\n",
    "                4. Avoid overly technical language unless the target audience is highly technical.\n",
    "                5. Maintain a friendly yet professional tone.\n",
    "            Output Format:\n",
    "                - Provide the blog post as markdown with section headings.\n",
    "                - Do not include any placeholder text â€” fully write out all sections.\n",
    "                - Keep word count between 500 and 600 words.\n",
    "            \"\"\"\n",
    "\n",
    "blog_post_agent = LlmAgent(\n",
    "    name=\"BlogPostAgent\", \n",
    "    model = os.getenv(\"GEMINI_VERSION\"),\n",
    "    description=(\"Agent that writes a 400-500 word announcement blog post\"),\n",
    "    instruction=blog_post_instructions, \n",
    "    generate_content_config=generate_content_config,\n",
    "    output_key=\"result\")\n",
    "\n",
    "blog_app = AdkApp(agent=blog_post_agent)\n",
    "print(\"âœ… BlogPostAgent is ready to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4551f-6213-4631-b25d-a2f507e63a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Local test of Blog Agent\n",
    "for event in blog_app.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    message=\"\"\"I want to announce a new product called VisionLink Pro.\n",
    "                Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration.\n",
    "                The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video.\n",
    "                The target audience is remote teams, global companies, and project managers.\n",
    "                \"\"\",):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b821aba-9869-4061-a5b3-8b73beafc81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Social Media LLM Agent\n",
    "from google.adk.agents import LlmAgent, ParallelAgent\n",
    "from google.genai import types\n",
    "from vertexai.preview.reasoning_engines import AdkApp\n",
    "\n",
    "# --- Set safety settings:\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "]\n",
    "\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "   safety_settings=safety_settings,\n",
    "   temperature=0.7,\n",
    "   max_output_tokens= 800,\n",
    "   top_p= 0.90,\n",
    ")\n",
    "\n",
    "\n",
    "social_media_instructions = \"\"\"\n",
    "        You are a social media coordinator responsible for creating short-form promotional posts for a new product launch.\n",
    "\n",
    "        Goal: \n",
    "        - Based on the provided product brief, generate engaging, platform-specific posts. \n",
    "        - If the brief does NOT specify platforms, default to LinkedIn, Twitter, and Instagram. \n",
    "        - If the user explicitly requests one or more platforms, generate posts only for those platforms.\n",
    "\n",
    "        Your responsibilities:\n",
    "        1. Accept a simple product brief with:\n",
    "           - Product Name\n",
    "           - Short Description\n",
    "           - Key Features (bullet list)\n",
    "           - Target Audience\n",
    "           - (Optional) Social Platforms: one or more platforms requested by the user (e.g., LinkedIn, Twitter, Instagram, TikTok, Facebook, YouTube Shorts, Reddit, Threads, Pinterest).\n",
    "        2. Select target platforms:\n",
    "           - If platforms are provided in the brief or prompt, use exactly those.\n",
    "           - Otherwise, default to: LinkedIn, Twitter, Instagram.\n",
    "           - Normalize synonyms: treat \"X\" or \"X/Twitter\" as \"Twitter\".\n",
    "        3. Create distinct, on-brand short-form posts tailored to each selected platform:\n",
    "           - LinkedIn: Professional tone, highlights business value, up to 100 words.\n",
    "           - Twitter: Punchy, attention-grabbing, max 280 characters.\n",
    "           - Instagram: Engaging, visually descriptive caption with relevant hashtags (max 10).\n",
    "           - If a different platform is requested, adapt tone/length to that platformâ€™s norms and limits.\n",
    "        4. Ensure each post reflects the platformâ€™s tone and constraints. Avoid generic filler; make every word impactful.\n",
    "\n",
    "        Output Format (strict):\n",
    "        - Return a single JSON object with one key per selected platform.\n",
    "        - Use exact platform keys (e.g., \"LinkedIn\", \"Twitter\", \"Instagram\", \"TikTok\", \"Facebook\", \"YouTube Shorts\", \"Reddit\", \"Threads\", \"Pinterest\").\n",
    "        - Do NOT wrap the JSON in code fences or add extra commentary.\n",
    "\n",
    "        Default example shape (when no platforms are specified):\n",
    "        {\n",
    "          \"LinkedIn\": \"Full LinkedIn post text\",\n",
    "          \"Twitter\": \"Full Twitter post text\",\n",
    "          \"Instagram\": \"Full Instagram caption text\"\n",
    "        }\n",
    "\n",
    "        Additional Notes:\n",
    "        - Ensure all content is original and aligned to the specified target audience.\n",
    "        - Include a clear hook or CTA where appropriate.\n",
    "        - For Instagram, ensure hashtags are relevant and non-repetitive.\n",
    "        - No placeholders like [link]; if a URL is not provided, omit it gracefully.\n",
    "        \"\"\"\n",
    "\n",
    "social_media_agent = LlmAgent(\n",
    "    name=\"SocialMediaAgent\", \n",
    "    model = os.getenv(\"GEMINI_VERSION\"),\n",
    "    description=(\"Agent that generates multi-platform short-form posts in structured JSON.\"),\n",
    "    instruction=social_media_instructions, \n",
    "    generate_content_config=generate_content_config,\n",
    "    output_key=\"result\")\n",
    "\n",
    "social_app = AdkApp(agent=social_media_agent)\n",
    "print(\"âœ… SocialMediaAgent is ready to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1b671-0032-4f80-9fa7-c269c70e0c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Local Test of Social Media Agent\n",
    "for event in social_app.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    message=\"\"\"\n",
    "    I want to announce a new product called VisionLink Pro.\n",
    "    Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration.\n",
    "    The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video.\n",
    "    The target audience is remote teams, global companies, and project managers.\n",
    "    \"\"\",):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c8570-12e6-43dd-80c5-d4a6e5c52426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Agent that will call both Blog and Social Agents in parallel (Used by Coordinator)\n",
    "gather_agent = ParallelAgent(name=\"InfoGatherer\", sub_agents=[blog_post_agent, social_media_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed2499-ff93-48cc-a0be-7deafc89deb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Create Coordinator LLM Agent -> SubAgent InfoGatherer\n",
    "campaign_coordinator_system_instructions = \"\"\"\n",
    "You are the Campaign Coordinator, an orchestrator agent that manages the end-to-end content creation workflow for a product launch.\n",
    "\n",
    "Goal\n",
    "Given a product brief, call InfoGatherer and return a single, cohesive campaign package as either:\n",
    "- A unified JSON object, or\n",
    "- A formatted Markdown file (preferred for human review).\n",
    "\n",
    "Inputs\n",
    "A simple product brief containing:\n",
    "- Product Name\n",
    "- Short Description\n",
    "- Key Features (bullet list)\n",
    "- Target Audience\n",
    "\n",
    "Available Tools / Sub-Agents\n",
    "- InfoGatherer -> Parallel Agent that returns the results of both BlogPostAgent and SocialMediaAgent\n",
    "\n",
    "Workflow\n",
    "1) Validate Brief\n",
    "   - Ensure required fields are present and non-empty.\n",
    "   - Normalize keys and trim whitespace. If anything critical is missing, add it under notes.missing_fields in the final output.\n",
    "\n",
    "2) Plan & Call Sub-Agents\n",
    "   - Call InfoGatherer unless explicitly disabled in the brief.\n",
    "   - Pass the brief verbatim and include goal hints:\n",
    "     * BlogPostAgent: \"Produce a 500â€“600 word launch post.\"\n",
    "     * SocialMediaAgent: \"Produce Social Media posts as specified.\"\n",
    "   - On failure, retry once. If still failing, continue and record under notes.errors.\n",
    "\n",
    "3) Consolidate & Harmonize\n",
    "   - Check social posts align factually with the blog post and brief (no contradictions).\n",
    "   - Unify tone: friendly, professional, concise (unless the audience is explicitly technical).\n",
    "   - Extract a single launch CTA and ensure it appears across channels (rephrased as needed).\n",
    "\n",
    "4) Output\n",
    "   - If output_format == \"json\", return the following JSON shape:\n",
    "     {\n",
    "       \"brief\": {\n",
    "         \"product_name\": \"...\",\n",
    "         \"short_description\": \"...\",\n",
    "         \"key_features\": [\"...\"],\n",
    "         \"target_audience\": \"...\"\n",
    "       },\n",
    "       \"assets\": {\n",
    "         \"blog_post_markdown\": \"## Title...\\\\n...\",\n",
    "         \"social_posts\": {\n",
    "           \"LinkedIn\": \"...\",\n",
    "           \"Twitter\": \"...\",\n",
    "           \"Instagram\": \"...\"\n",
    "         }\n",
    "       },\n",
    "       \"consistency_check\": {\n",
    "         \"facts_confirmed\": [\"...\"],\n",
    "         \"potential_gaps\": [\"...\"]\n",
    "       },\n",
    "       \"notes\": {\n",
    "         \"missing_fields\": [],\n",
    "         \"errors\": []\n",
    "       }\n",
    "     }\n",
    "\n",
    "   - If output_format == \"markdown\" (default), return:\n",
    "     \"# Campaign Package: <Product Name>\\\\n\\\\n## Blog Post\\\\n<full blog post markdown>\\\\n\\\\n## Social Posts\\\\n- **LinkedIn:** <text>\\\\n- **Twitter:** <text>\\\\n- **Instagram:** <caption>\\\\n\\\\n---\\\\n### Consistency Check\\\\n- Facts confirmed: â€¦\\\\n- Potential gaps: â€¦\\\\n\\\\n### Notes\\\\n- Missing fields: â€¦\\\\n- Errors: â€¦\"\n",
    "\n",
    "Quality Bar\n",
    "- No hallucinated facts; only use the brief and sub-agent outputs.\n",
    "- Respect platform constraints (e.g., Twitter â‰¤ 280 chars).\n",
    "- Remove repetitive hashtags and unnecessary jargon.\n",
    "- Ensure spelling and grammar are clean across all assets.\n",
    "\n",
    "Failure Handling\n",
    "- If a sub-agent returns empty or invalid output:\n",
    "  - Retry once.\n",
    "  - If still invalid, omit that asset, record under notes.errors, and proceed.\n",
    "\"\"\"\n",
    "\n",
    "coordinator_agent = LlmAgent(\n",
    "    name=\"CoordinatorAgent\",\n",
    "    model = os.getenv(\"GEMINI_VERSION\"),\n",
    "    instruction=campaign_coordinator_system_instructions,\n",
    "    description=\"Campaign Coordinator\",\n",
    "    sub_agents=[gather_agent] #parallel agent that executes both Blog and Social Agents\n",
    ")\n",
    "\n",
    "coordinator_app = AdkApp(agent=coordinator_agent)\n",
    "print(\"âœ… CoordinatorAgent is ready to be deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4c15f-8d5f-470b-90c5-005be0d8a0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Local test for Coordinator Agent\n",
    "for event in coordinator_app.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    message=\"\"\" Product Name: VisionLink Pro.\n",
    "                Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration.\n",
    "                The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video.\n",
    "                The target audience is remote teams, global companies, and project managers.\n",
    "                Platforms: LinkedIn, Instagram\n",
    "                \"\"\",):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917bd80-d38e-4149-aba0-5bf8e51f96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Deploy all Agents in Vertex AI Agent Engine (Wait for Creation of all agents before moving on...)\n",
    "import vertexai\n",
    "\n",
    "from vertexai import agent_engines\n",
    "\n",
    "# --- Init Vertex AI Environment ---\n",
    "vertexai.init(\n",
    "    project= os.getenv(\"GOOGLE_CLOUD_PROJECT\"),\n",
    "    location= os.getenv(\"GOOGLE_CLOUD_LOCATION\"),\n",
    "    staging_bucket= os.getenv(\"GOOGLE_CLOUD_BUCKET\"), \n",
    ")\n",
    "\n",
    "# --- Deploy Blog Post Agent ---\n",
    "remote_blog_agent = agent_engines.create(\n",
    "    blog_app,\n",
    "    display_name=\"Blog Post Agent\",\n",
    "    description=\"Writes 400â€“600 word product announcement posts in Markdown.\",\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"],  #\"cloudpickle==3.1.1\",\"pydantic==2.11.7\"\n",
    ")\n",
    "print(\"âœ… Blog Post Agent created on Vertex AI Agent Engine\")\n",
    "\n",
    "# --- Deploy Social Media Agent ---\n",
    "remote_social_agent = agent_engines.create(\n",
    "    social_app,\n",
    "    display_name=\"Social Media Agent\",\n",
    "    description=\"Generates multi-platform short-form posts in structured JSON from a product brief.\",\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"], \n",
    ")\n",
    "print(\"âœ… Social Media Agent created on Vertex AI Agent Engine\")\n",
    "\n",
    "# --- Deploy Campaign Coordinator Agent ---\n",
    "remote_campaign_coordinator_agent = agent_engines.create(\n",
    "    coordinator_app,\n",
    "    display_name=\"Campaign Coordinator Agent\",\n",
    "    description=\"Orchestrates Blog Post and Social Media Agents to produce a unified campaign package.\",\n",
    "    requirements=[\"google-cloud-aiplatform[agent_engines,adk]\"],\n",
    ")\n",
    "print(\"âœ… Campaign Coordinator Agent created on Vertex AI Agent Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac398de6-69f0-4831-b54d-a50dbcd4f069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Test consolidation of Blog + Social Media Agent\n",
    "remote_session = remote_campaign_coordinator_agent.create_session(user_id=\"user_123\")\n",
    "\n",
    "for event in remote_campaign_coordinator_agent.stream_query(\n",
    "    user_id=\"user_123\",\n",
    "    session_id = remote_session[\"id\"],\n",
    "    message=\"\"\"I want to announce a new product called VisionLink Pro.\n",
    "                Itâ€™s an AI-powered video conferencing platform that improves communication with real-time translation, automatic meeting summaries, and calendar integration. \n",
    "                The main features include support for 25+ languages, Slack + Google Calendar integration, and high-definition audio and video. \n",
    "                The target audience is remote teams, global companies, and project managers.\"\"\"\n",
    "   ):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a311090-2e59-4ba6-afea-00618ba9afec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gradio_agent_console.py\n",
    "# ------------------------------------------------------------\n",
    "# Gradio UI for 3 Vertex AI Agent Engine agents (ADK style)\n",
    "# - Left pane: Agent selector, sample prompts, prompt box, Send\n",
    "# - Right pane: Chatbot (per-agent history), session-aware\n",
    "# - Controls: New Session (per-agent), Clear Chat (keep session)\n",
    "\n",
    "# Docs:\n",
    "#   - Use an agent (query/stream_query): https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/use/overview\n",
    "#   - ADK sessions (create_session/stream_query with session_id): https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/use/adk\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "import vertexai\n",
    "from vertexai import agent_engines\n",
    "\n",
    "# ---------------------- CONFIG ------------------------------\n",
    "# Set these to your deployed Agent Engine resource names.\n",
    "BLOG_AGENT_RESOURCE        = remote_blog_agent.resource_name\n",
    "SOCIAL_AGENT_RESOURCE      = remote_social_agent.resource_name\n",
    "COORDINATOR_AGENT_RESOURCE = remote_campaign_coordinator_agent.resource_name\n",
    "\n",
    "AGENT_LABELS = {\n",
    "    \"ðŸ“ Blog Post Agent\": BLOG_AGENT_RESOURCE,\n",
    "    \"ðŸ“£ Social Media Agent\": SOCIAL_AGENT_RESOURCE,\n",
    "    \"ðŸ§­ Campaign Coordinator Agent\": COORDINATOR_AGENT_RESOURCE,\n",
    "}\n",
    "\n",
    "# A stable user_id helps the Agent Engine associate sessions with your user.\n",
    "DEFAULT_USER_ID = \"UI-user\"\n",
    "\n",
    "# ---- Simple labels for the dropdown; full text inserted into the Prompt box ----\n",
    "SAMPLE_PROMPT_MAP = {\n",
    "    \"NimbusNote Pro (consultants)\": (\n",
    "        \"Create launch content using this brief: The product is NimbusNote Pro, an AI-powered note-taking app that helps \"\n",
    "        \"consultants organize client work, auto-summarize meetings, and draft deliverables faster. Key features include AI summaries \"\n",
    "        \"with action items, cross-device sync with offline mode, project spaces with permissions, export to PDF/DOCX/Markdown, and \"\n",
    "        \"ready-to-use templates for proposals and SOWs. The target audience is management consultants and knowledge workers in SMB \"\n",
    "        \"and mid-market firms. For social, focus on LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"AeroLens 2.0 (field service)\": (\n",
    "        \"Create launch content using this brief: The product is AeroLens 2.0, lightweight AR glasses for field technicians that \"\n",
    "        \"overlay step-by-step guidance and capture hands-free photos and video. Key features include on-device offline manuals, \"\n",
    "        \"voice commands with gesture control, remote expert assistance, a rugged design with all-day battery, and work order sync \"\n",
    "        \"with popular EAM/CMMS tools. The target audience is utilities, manufacturing, and field service teams. For social, focus on \"\n",
    "        \"LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"SparkBrew (home office coffee)\": (\n",
    "        \"Create launch content using this brief: The product is SparkBrew, a smart coffee maker for home offices with precise \"\n",
    "        \"temperature control and scheduled brewing via a mobile app. Key features include barista-grade temperature and bloom control, \"\n",
    "        \"brew scheduling with reminders, custom profiles by roast, cleaning alerts with a maintenance log, and a compact low-noise \"\n",
    "        \"design. The target audience is remote professionals and small office teams. For social, focus on LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"FleetSense (fleet IoT)\": (\n",
    "        \"Create launch content using this brief: The product is FleetSense, an IoT fleet platform that monitors vehicle health, \"\n",
    "        \"driver behavior, and routing to reduce fuel costs and downtime. Key features include real-time GPS with geofencing, predictive \"\n",
    "        \"maintenance alerts, driver safety scoring, fuel optimization insights, and open APIs for TMS/ERP integration. The target \"\n",
    "        \"audience is logistics managers and operations leaders in fleet-heavy businesses. For social, focus on LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"ClaraPay (AP automation)\": (\n",
    "        \"Create launch content using this brief: The product is ClaraPay, a B2B payments automation solution that streamlines invoice \"\n",
    "        \"capture, approvals, and reconciliation within existing accounting stacks. Key features include OCR with AI data extraction, \"\n",
    "        \"multistep approvals with thresholds, vendor management with 1099 support, automated three-way matching, and ERP connectors for \"\n",
    "        \"QuickBooks, NetSuite, and Xero. The target audience is SMB and mid-market finance teams in AP/AR. For social, focus on \"\n",
    "        \"LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"Gardenie One (indoor smart garden)\": (\n",
    "        \"Create launch content using this brief: The product is Gardenie One, an indoor smart garden that grows herbs and greens \"\n",
    "        \"year-round with automatic lighting and watering. Key features include adaptive LED grow cycles, a self-watering reservoir, \"\n",
    "        \"app-based growth tips and reminders, non-GMO seed pods, and dishwasher-safe trays. The target audience is health-conscious home \"\n",
    "        \"cooks and apartment dwellers. For social, focus on LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"CodeZen AI (Python devs)\": (\n",
    "        \"Create launch content using this brief: The product is CodeZen AI, an AI pair programmer for Python that suggests tests, \"\n",
    "        \"explains errors, and enforces a teamâ€™s style guide. Key features include inline suggestions and refactors, unit-test generation \"\n",
    "        \"with coverage hints, CI-ready linting presets (Black and Flake8), repo-aware context windows, and security checks for secrets and SQL. \"\n",
    "        \"The target audience is Python engineering teams at startups and SaaS companies. For social, focus on LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "    \"LumaDesk Glow (smart desk lamp)\": (\n",
    "        \"Create launch content using this brief: The product is LumaDesk Glow, a smart LED desk lamp that adapts brightness and color \"\n",
    "        \"temperature to your circadian rhythm for better focus. Key features include automatic ambient light sensing, a warm-to-cool \"\n",
    "        \"temperature range, eye-strain reduction modes, app and voice assistant control, and energy usage insights. The target audience is \"\n",
    "        \"students, designers, and remote workers who need healthier work lighting. For social, focus on LinkedIn, X/Twitter, and Instagram.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "# If all agents share the same samples, just reuse the same label list:\n",
    "SAMPLE_LABELS = list(SAMPLE_PROMPT_MAP.keys())\n",
    "\n",
    "# ------------------ Agent Helpers ---------------------------\n",
    "def _get_agent(resource_name):\n",
    "    \"\"\"Return a remote agent object from Agent Engine.\"\"\"\n",
    "    return agent_engines.get(resource_name)\n",
    "\n",
    "def _create_session(agent, user_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a managed session via ADK-style op.\n",
    "    Returns session_id string.\n",
    "    \"\"\"\n",
    "    # ADK 'Use' doc exposes create_session(user_id=...) on the agent handle.\n",
    "    session = agent.create_session(user_id=user_id)\n",
    "    # session may be a dict or object with 'id'\n",
    "    if isinstance(session, dict):\n",
    "        return session.get(\"id\") or session.get(\"session_id\") or \"\"\n",
    "    return getattr(session, \"id\", \"\") or getattr(session, \"session_id\", \"\")\n",
    "\n",
    "def _extract_stream_output(event) -> str:\n",
    "    \"\"\"\n",
    "    Extract the most useful text from a streamed event.\n",
    "    For ADK stream_query, the final event often includes 'output'.\n",
    "    Earlier events may include 'actions' or 'steps'.\n",
    "    \"\"\"\n",
    "    # event might be dict-like already\n",
    "    if hasattr(event, \"to_dict\"):\n",
    "        try:\n",
    "            event = event.to_dict()\n",
    "        except Exception:\n",
    "            event = dict(event)\n",
    "    elif not isinstance(event, dict):\n",
    "        # Try best effort\n",
    "        try:\n",
    "            event = json.loads(str(event))\n",
    "        except Exception:\n",
    "            return str(event)\n",
    "\n",
    "    # Priority: 'output' field\n",
    "    out = event.get(\"output\")\n",
    "    if isinstance(out, (str, int, float)):\n",
    "        return str(out)\n",
    "    if isinstance(out, (dict, list)):\n",
    "        try:\n",
    "            return json.dumps(out, indent=2, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            return str(out)\n",
    "\n",
    "    # Fallbacks seen in some templates\n",
    "    for key in (\"result\", \"output_text\", \"message\", \"text\"):\n",
    "        val = event.get(key)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val\n",
    "\n",
    "    # If there's a 'content' shape with 'parts'\n",
    "    content = event.get(\"content\")\n",
    "    if isinstance(content, dict):\n",
    "        parts = content.get(\"parts\") or []\n",
    "        texts = []\n",
    "        for p in parts:\n",
    "            t = p.get(\"text\")\n",
    "            if isinstance(t, str) and t.strip():\n",
    "                texts.append(t.strip())\n",
    "        if texts:\n",
    "            return \"\\n\".join(texts)\n",
    "\n",
    "    # Nothing obvious\n",
    "    return \"\"\n",
    "\n",
    "def _stream_agent_reply(agent, user_id: str, session_id: str, message: str) -> str:\n",
    "    \"\"\"\n",
    "    Call stream_query and return the final consolidated text.\n",
    "    We join partial readable chunks and prefer the final 'output' if present.\n",
    "    \"\"\"\n",
    "    final_text = \"\"\n",
    "    collected = []\n",
    "    # ADK 'Use' doc supports stream_query(user_id=..., session_id=..., message=...)\n",
    "    for ev in agent.stream_query(user_id=user_id, session_id=session_id, message=message):\n",
    "        chunk = _extract_stream_output(ev)\n",
    "        if chunk:\n",
    "            collected.append(chunk)\n",
    "            final_text = chunk  # last non-empty chunk usually the final answer\n",
    "\n",
    "    # If we saw only partials and no clear final, return the concatenation.\n",
    "    if final_text:\n",
    "        return final_text\n",
    "    if collected:\n",
    "        return \"\\n\".join(collected)\n",
    "    return \"[no output]\"\n",
    "\n",
    "# ------------------ Gradio Callbacks ------------------------\n",
    "def on_agent_change(agent_label: str):\n",
    "    \"\"\"Update samples and (optionally) placeholder when agent changes.\"\"\"\n",
    "    return gr.update(choices=SAMPLE_LABELS, value=None), gr.update(value=\"\")\n",
    "\n",
    "def on_sample_label_change(sample_label: str):\n",
    "    # insert the full prompt text into the textbox\n",
    "    return SAMPLE_PROMPT_MAP.get(sample_label, \"\")\n",
    "\n",
    "def ensure_session_for_agent(agent_label: str, sessions_state: dict, user_id: str):\n",
    "    \"\"\"Fetch or create a session for the selected agent.\"\"\"\n",
    "    sessions_state = sessions_state or {}\n",
    "    sid = sessions_state.get(agent_label)\n",
    "    if sid:\n",
    "        return sid, sessions_state  # re-use\n",
    "    agent = _get_agent(AGENT_LABELS[agent_label])\n",
    "    new_sid = _create_session(agent, user_id=user_id)\n",
    "    sessions_state[agent_label] = new_sid\n",
    "    return new_sid, sessions_state\n",
    "\n",
    "# ------------------Formatting----------------------\n",
    "import re, json\n",
    "\n",
    "CODE_FENCE_JSON_RE = re.compile(r\"```json\\s*(.*?)\\s*```\", re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "def _maybe_parse_json(text: str):\n",
    "    \"\"\"Return parsed JSON (dict/list) if text contains valid JSON; else None.\n",
    "    Handles ```json fences``` and bare JSON blobs.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return None\n",
    "\n",
    "    # 1) Try fenced ```json ... ```\n",
    "    m = CODE_FENCE_JSON_RE.search(text)\n",
    "    if m:\n",
    "        try:\n",
    "            return json.loads(m.group(1))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) Try full text as JSON\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Fallback: find the biggest {...} and try\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        candidate = text[start:end+1]\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def _format_social_posts_md(data: dict) -> str:\n",
    "    li = data.get(\"LinkedIn\") or data.get(\"linkedin\")\n",
    "    tw = data.get(\"Twitter\") or data.get(\"X\") or data.get(\"x_twitter\") or data.get(\"twitter\")\n",
    "    ig = data.get(\"Instagram\") or data.get(\"instagram\")\n",
    "    out = [\"### Social Posts\"]\n",
    "    if li: out.append(f\"- **LinkedIn:** {li}\")\n",
    "    if tw: out.append(f\"- **Twitter/X:** {tw}\")\n",
    "    if ig: out.append(f\"- **Instagram:** {ig}\")\n",
    "    return \"\\n\".join(out) if len(out) > 1 else \"```json\\n\" + json.dumps(data, indent=2, ensure_ascii=False) + \"\\n```\"\n",
    "\n",
    "def _format_coordinator_md(pkg: dict) -> str:\n",
    "    brief = pkg.get(\"brief\") or {}\n",
    "    assets = pkg.get(\"assets\") or {}\n",
    "    blog = assets.get(\"blog_post_markdown\") or assets.get(\"blog_post\") or \"\"\n",
    "    social = assets.get(\"social_posts\") or {}\n",
    "\n",
    "    title = brief.get(\"product_name\") or brief.get(\"Product Name\") or \"Campaign Package\"\n",
    "    parts = [f\"# Campaign Package: {title}\"]\n",
    "\n",
    "    if blog:\n",
    "        parts += [\"\", \"## Blog Post\", blog.strip()]\n",
    "\n",
    "    if social:\n",
    "        parts += [\"\", _format_social_posts_md(social)]\n",
    "\n",
    "    # Optional diagnostics\n",
    "    cc = pkg.get(\"consistency_check\")\n",
    "    if cc:\n",
    "        parts += [\"\", \"### Consistency Check\", \"```json\", json.dumps(cc, indent=2, ensure_ascii=False), \"```\"]\n",
    "\n",
    "    notes = pkg.get(\"notes\")\n",
    "    if notes:\n",
    "        parts += [\"\", \"### Notes\", \"```json\", json.dumps(notes, indent=2, ensure_ascii=False), \"```\"]\n",
    "\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def _format_for_display(agent_label: str, raw_text: str) -> str:\n",
    "    \"\"\"Turn any agent output into nice markdown for the Chatbot.\"\"\"\n",
    "    data = _maybe_parse_json(raw_text)\n",
    "\n",
    "    # If JSON detected, format intelligently\n",
    "    if data is not None:\n",
    "        # Social posts shape\n",
    "        if isinstance(data, dict) and any(k in data for k in (\"LinkedIn\", \"linkedin\", \"Twitter\", \"X\", \"Instagram\")):\n",
    "            return _format_social_posts_md(data)\n",
    "\n",
    "        # Coordinator package shape\n",
    "        if isinstance(data, dict) and (\"assets\" in data or \"brief\" in data):\n",
    "            return _format_coordinator_md(data)\n",
    "\n",
    "        # Unknown JSON â†’ pretty-print\n",
    "        return \"```json\\n\" + json.dumps(data, indent=2, ensure_ascii=False) + \"\\n```\"\n",
    "\n",
    "    # No JSON â†’ likely plain markdown/text (e.g., Blog agent)\n",
    "    return raw_text or \"[no output]\"\n",
    "\n",
    "\n",
    "def send_message(agent_label: str, prompt_text: str, chat_map: dict, sessions_state: dict, user_id: str):\n",
    "    \"\"\"\n",
    "    Send the message to the selected agent using the persisted session.\n",
    "    Returns updated chatbot content and states.\n",
    "    \"\"\"\n",
    "    chat_map = chat_map or {}\n",
    "    chat = _to_messages(chat_map.get(agent_label, []))\n",
    "\n",
    "    if not prompt_text or not prompt_text.strip():\n",
    "        return chat, chat_map, sessions_state, gr.update(value=\"\")  # no change\n",
    "\n",
    "    # Ensure session\n",
    "    session_id, sessions_state = ensure_session_for_agent(agent_label, sessions_state, user_id)\n",
    "    agent = _get_agent(AGENT_LABELS[agent_label])\n",
    "\n",
    "    # Call the agent (streaming) and collect final text\n",
    "    try:\n",
    "        raw_reply = _stream_agent_reply(agent, user_id=user_id, session_id=session_id, message=prompt_text.strip())\n",
    "        reply_text = _format_for_display(agent_label, raw_reply)\n",
    "    except Exception as e:\n",
    "        reply_text = f\"[stream_query failed] {e}\"\n",
    "\n",
    "    chat.append({\"role\": \"user\", \"content\": prompt_text})\n",
    "    chat.append({\"role\": \"assistant\", \"content\": reply_text})\n",
    "    chat_map[agent_label] = chat\n",
    "    return chat, chat_map, sessions_state, gr.update(value=\"\")\n",
    "\n",
    "def new_session(agent_label: str, chat_map: dict, sessions_state: dict, user_id: str):\n",
    "    \"\"\"Create a fresh session for the selected agent and clear only that agent's chat.\"\"\"\n",
    "    chat_map = chat_map or {}\n",
    "    sessions_state = sessions_state or {}\n",
    "\n",
    "    agent = _get_agent(AGENT_LABELS[agent_label])\n",
    "    sid = _create_session(agent, user_id=user_id)\n",
    "\n",
    "    sessions_state[agent_label] = sid\n",
    "    chat_map = chat_map or {}\n",
    "    chat_map[agent_label] = []\n",
    "    return chat_map[agent_label], chat_map, sessions_state\n",
    "\n",
    "def clear_chat_only(agent_label: str, chat_map: dict):\n",
    "    \"\"\"Clear chat history for the selected agent but keep the session.\"\"\"\n",
    "    chat_map = chat_map or {}\n",
    "    chat_map[agent_label] = []\n",
    "    return chat_map[agent_label], chat_map\n",
    "\n",
    "def _to_messages(history):\n",
    "    if not history: return []\n",
    "    if isinstance(history, list) and (not history or isinstance(history[0], dict)):\n",
    "        return history\n",
    "    msgs = []\n",
    "    for u, a in history:\n",
    "        if isinstance(u, str) and u.strip():\n",
    "            msgs.append({\"role\": \"user\", \"content\": u})\n",
    "        if isinstance(a, str) and a.strip():\n",
    "            msgs.append({\"role\": \"assistant\", \"content\": a})\n",
    "    return msgs\n",
    "\n",
    "\n",
    "# ---------------------- UI -------------------------------\n",
    "with gr.Blocks(title=\"Eddy's LaunchPad: Agent Engine Console\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## ðŸš€ LaunchPad â€” Agent Engine Console\\nInteract with your deployed agents.\")\n",
    "\n",
    "    # Global state:\n",
    "    # - chat_map: { agent_label -> list[(user, bot), ...] }\n",
    "    # - sessions_state: { agent_label -> session_id }\n",
    "    chat_map = gr.State({})\n",
    "    sessions_state = gr.State({})\n",
    "    user_id_box = gr.Textbox(value=DEFAULT_USER_ID, label=\"User ID (for sessions)\", interactive=True)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, min_width=340):\n",
    "            agent_dd = gr.Dropdown(\n",
    "                choices=list(AGENT_LABELS.keys()),\n",
    "                value=\"ðŸ§­ Campaign Coordinator Agent\",\n",
    "                label=\"Select Agent\",\n",
    "                interactive=True,\n",
    "            )\n",
    "            sample_dd = gr.Dropdown(\n",
    "                choices=SAMPLE_LABELS,\n",
    "                label=\"Prompt Samples\",\n",
    "                interactive=True,\n",
    "                value=None  # start blank\n",
    "            )\n",
    "            prompt_tb = gr.Textbox(\n",
    "                label=\"Prompt\",\n",
    "                placeholder=\"Type your request for the selected agentâ€¦\",\n",
    "                lines=8,\n",
    "            )\n",
    "            with gr.Row():\n",
    "                send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "                new_sess_btn = gr.Button(\"New Session (Selected Agent)\", variant=\"secondary\")\n",
    "            clear_btn = gr.Button(\"Clear Chat (Selected Agent)\", variant=\"secondary\")\n",
    "\n",
    "        with gr.Column(scale=2, min_width=540):\n",
    "            session_id_display = gr.Textbox(label=\"Current Session ID (Selected Agent)\", interactive=False)\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"Conversation\",\n",
    "                type=\"messages\",\n",
    "                height=520\n",
    "            )\n",
    "\n",
    "    # --- Wiring ---\n",
    "    agent_dd.change(fn=on_agent_change, inputs=[agent_dd], outputs=[sample_dd, prompt_tb])\n",
    "    sample_dd.change(fn=on_sample_label_change, inputs=[sample_dd], outputs=[prompt_tb])\n",
    "\n",
    "    # Ensure we show the current session id on focus/agent change:\n",
    "    def refresh_session_id(agent_label, sessions_state, user_id):\n",
    "        sid, sessions_state = ensure_session_for_agent(agent_label, sessions_state, user_id)\n",
    "        return sid, sessions_state\n",
    "    agent_dd.change(fn=refresh_session_id, inputs=[agent_dd, sessions_state, user_id_box], outputs=[session_id_display, sessions_state])\n",
    "\n",
    "    send_btn.click(\n",
    "        fn=send_message,\n",
    "        inputs=[agent_dd, prompt_tb, chat_map, sessions_state, user_id_box],\n",
    "        outputs=[chatbot, chat_map, sessions_state, prompt_tb],\n",
    "    ).then(\n",
    "        fn=refresh_session_id,\n",
    "        inputs=[agent_dd, sessions_state, user_id_box],\n",
    "        outputs=[session_id_display, sessions_state]\n",
    "    )\n",
    "\n",
    "    new_sess_btn.click(\n",
    "        fn=new_session,\n",
    "        inputs=[agent_dd, chat_map, sessions_state, user_id_box],\n",
    "        outputs=[chatbot, chat_map, sessions_state],\n",
    "    ).then(\n",
    "        fn=refresh_session_id,\n",
    "        inputs=[agent_dd, sessions_state, user_id_box],\n",
    "        outputs=[session_id_display, sessions_state]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        fn=clear_chat_only,\n",
    "        inputs=[agent_dd, chat_map],\n",
    "        outputs=[chatbot, chat_map],\n",
    "    )\n",
    "\n",
    "# To run:\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd281a-dad8-45d3-985c-b70118c30bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cleanup Turn Off UI\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f540a-2f8e-474c-8ee3-38d1d1cf2b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- Cleanup Delete Deployed Agents\n",
    "remote_blog_agent.delete(force=True)\n",
    "remote_social_agent.delete(force=True)\n",
    "remote_campaign_coordinator_agent.delete(force=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
